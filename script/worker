#!/usr/bin/env perl
# Copyright (c) 2013 SUSE Linux Products GmbH
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

=head1 worker

worker - openQA worker daemon

=head1 SYNOPSIS

worker [OPTIONS]

=head1 OPTIONS

=over 4

=item B<--host> HOST

specify dispatcher/scheduler host to connect to

=item B<--instance> NR

specify instance number, ie pool directory to use

=item B<--apikey> <value>

specify the public key needed for API authentication

=item B<--apisecret> <value>

specify the secret key needed for API authentication

=item B<--isotovideo> PATH

path to isotovideo script, useful for running from git

=item B<--no-cleanup>

don't clean pool directory after job

=item B<--verbose>

verbose output

=item B<--help, -h>

print help

=back

=head1 DESCRIPTION

lorem ipsum ...

=head1 CONFIG FILE

L<OpenQA::Client> tries to find a config file in
$OPENQA_CLIENT_CONFIG, ~/.config/openqa/client.conf or
/etc/openqa/client.conf and reads whatever comes first.
You can put API key and secret in that config file.

Example:
  [openqa.example.com]
  key = foo
  secret = bar

=head1 SEE ALSO
L<OpenQA::Client>

=cut

use strict;
use warnings;
use POSIX qw/:sys_wait_h strftime SIGTERM SIGKILL uname/;
use Data::Dump;
use JSON;
use Fcntl;
use Config::IniFiles;
use File::Path qw/make_path remove_tree/;
use File::Copy qw(copy move);
use File::Copy::Recursive qw(dirmove);
use FindBin;
use Mojo::UserAgent;
use Mojo::URL;
use Mojo::IOLoop;
use Carp;
use lib "$FindBin::Bin/../lib";
use lib "$FindBin::Bin/../lib/OpenQA";
use OpenQA::Utils ();
use OpenQA::Client;
use IPC::Open3;

my $max_job_time;
my $status_updates_slow = 5;
my $status_updates_fast = 0.5;
my $openqa_base = "/var/lib/openqa";
my $openqa_share = "$openqa_base/share";
my $pooldir;
my $assetdir = "$openqa_share/factory";
my $isodir = "$assetdir/iso";
my $hdddir = "$assetdir/hdd";
my $results_dir = "$openqa_share/testresults";

my $isotovideo = "/usr/bin/isotovideo";

my $log_offset = 0;

use Getopt::Long;
Getopt::Long::Configure("no_ignore_case");

my %options;
my $worker_settings;

sub usage($) {
    my $r = shift;
    eval "use Pod::Usage; pod2usage($r);";
    if ($@) {
        die "cannot display help, install perl(Pod::Usage)\n";
    }
}

GetOptions(\%options,"no-cleanup","instance=i","isotovideo=s","host=s","apikey:s","apisecret:s","verbose|v","help|h",) or usage(1);

usage(0) if ($options{'help'});

my $verbose = $options{'verbose'};

$options{'instance'} ||= 0;

my ($sysname, $hostname, $release, $version, $machine) = POSIX::uname();

my $job;
my $worker;
my $workerid;
my $worker_start_time;
my $testresults;
my $worker_caps;

## Mojo timers ids
my $timers = {
    # check for commands from scheduler
    'ws_keepalive' => undef,
    # check for new job
    'check_job'       => undef,
    # update status of running job
    'update_status'   => undef,
    # check for crashed backend and its running status
    'check_backend'   => undef,
    # trigger stop_job if running for > $max_job_time
    'job_timeout'     => undef
};


sub add_timer {
    my ($timer, $timeout, $callback, $nonrecurring) = @_;
    return unless ($timer && $timeout && $callback);
    return if ($timers->{$timer});
    print "## adding timer $timer\n" if $verbose;
    my $timerid;
    if ($nonrecurring) {
        $timerid = Mojo::IOLoop->timer( $timeout => $callback);
    }
    else {
        $timerid = Mojo::IOLoop->recurring( $timeout => $callback);
    }
    $timers->{$timer} = [$timerid, $callback];
    return $timerid;
}

sub remove_timer {
    my ($timer) = @_;
    return unless ($timer && $timers->{$timer});
    print "## removing timer $timer\n" if $verbose;
    Mojo::IOLoop->remove($timers->{$timer}->[0]);
    $timers->{$timer} = undef;
}

sub change_timer {
    my ($timer, $newtimeout, $callback) = @_;
    return unless ($timer && $timers->{$timer});
    print "## changing timer $timer\n" if $verbose;
    $callback = $timers->{$timer}->[1] unless $callback;
    remove_timer($timer);
    add_timer($timer, $newtimeout, $callback);
}

sub read_worker_config($){
    my $instance = shift;
    my $worker_config = "/etc/openqa/workers.ini";
    my $cfg = Config::IniFiles->new( -file => "$worker_config" );
    my $sets = {};
    foreach my $section ('global', $instance) {
        if($cfg && $cfg->SectionExists($section)) {
            foreach my $set ($cfg->Parameters($section)) {
                $sets->{uc $set} = $cfg->val($section, $set);
            }
        }
    }
    $sets->{'BACKEND'} ||= "qemu";
    $sets->{'HOST'} ||= "localhost";
    return $sets;
}

$worker_settings = read_worker_config($options{'instance'});

$options{'host'} ||= $worker_settings->{'HOST'};

# $ws is websocket connection
my $ws;
my $url;
if ($options{'host'} !~ '/') {
    $url = Mojo::URL->new();
    $url->host($options{'host'});
    $url->scheme('http');
}
else {
    $url = Mojo::URL->new($options{'host'});
}
# Relative paths are appended to the existing one
$url->path('/api/v1/');

my $ua = OpenQA::Client->new(
    api => $url->host,
    apikey => $options{'apikey'},
    apisecret => $options{'apisecret'}
);

unless ($ua->apikey && $ua->apisecret) {
    unless ($options{'apikey'} && $options{apisecret}) {
        die "API key and secret are needed for the worker connecting " . $url->host . "\n";
    }

    $ua->apikey($options{'apikey'});
    $ua->apisecret($options{'apisecret'});
}

$pooldir = $openqa_base.'/pool/'.($options{'instance'}||'manual');

# XXX: this should be sent to the scheduler to be included in the worker's table
$ENV{'QEMUPORT'} = ($options{'instance'})*10 + 20002;
$ENV{'VNC'}      = ($options{'instance'})    + 90;
$ENV{'OPENQA_HOSTNAME'} = $url->authority;

$isotovideo = $options{'isotovideo'} if $options{'isotovideo'};

# send a command to openQA API
sub api_call {
    my $method = lc(shift);
    my $path = shift;
    my $params = shift;
    my $json_data = shift;
    my $ua_url = $url->clone;

    $ua_url->path($path =~ s/^\///r);
    $ua_url->query($params) if $params;

    my $tries = 3;
    while (1) {
        print uc($method) . " $ua_url\n" if $verbose;
        my $tx;
        if ($json_data) {
            $tx = $ua->$method($ua_url => json => $json_data);
        }
        else {
            $tx = $ua->$method($ua_url);
        }
        if ($tx->success) {
            return $tx->success->json;
        }
        --$tries;
        my ($err, $code) = $tx->error;
        my $msg = $code ? "$tries: $code response: $err" : "$tries: Connection error: $err->{message}";
        carp "$msg";
        if (!$tries) {
            # abort the current job, we're in trouble - but keep running to grab the next
            stop_job('api-failure');
            return undef;
        }
        sleep 5;
    }
}

sub lockit(){
    if (!-e $pooldir) {
        make_path($pooldir);
    }
    chdir $pooldir || die "cannot change directory to $pooldir: $!\n";
    open(my $lockfd, '>>', '.locked') or die "cannot open lock file: $!\n";
    unless (fcntl($lockfd, F_SETLK, pack('ssqql', F_WRLCK, 0, 0, 0, $$))) {
        die "$pooldir already locked\n";
    }
    $lockfd->autoflush(1);
    truncate($lockfd, 0);
    print $lockfd "$$\n";
    return $lockfd;
}

sub workit($){
    my $job = shift;

    # XXX: this should come from the worker table. Only included
    # here for convenience when looking at the pool of
    # debugging.
    for my $i (qw/QEMUPORT VNC OPENQA_HOSTNAME/) {
        $job->{settings}->{$i} = $ENV{$i};
    }
    if (open(my $fh, '>', 'job.json')) {
        print $fh to_json($job, { pretty => 1 });
        close $fh;
    }

    # always set proper TAPDEV for os-autoinst when using tap network mode
    # ensure MAC addresses differ, tap devices may be bridged together
    # and allow MAC addresses for more than 256 workers (up to 65535)
    if (($job->{'settings'}->{'NICTYPE'}//'') eq 'tap') {
        $job->{'settings'}->{'TAPDEV'} = 'tap' . ($options{'instance'} - 1);
        $job->{'settings'}->{'NICMAC'} = sprintf("52:54:00:12:%02x:%02x", int($options{'instance'} / 256), $options{'instance'} % 256);
    }

    if (my $iso = $job->{'settings'}->{'ISO'}) {
        $iso = join('/', $isodir, $iso);
        unless (-e $iso) {
            warn "$iso does not exist!\n";
            return undef;
        }
        $job->{'settings'}->{'ISO'} = $iso;
    }

    my $nd = $job->{'settings'}->{'NUMDISKS'} || 2;
    for my $i (1..$nd) {
        my $hdd = $job->{'settings'}->{"HDD_$i"} || undef;
        if ($hdd) {
            $hdd = join('/', $hdddir, $hdd);
            unless (-e $hdd) {
                warn "$hdd does not exist!\n";
                return undef;
            }
            $job->{'settings'}->{"HDD_$i"} = $hdd;
        }
    }

    my %vars = ();
    while (my ($k, $v) = each %{$job->{'settings'}}) {
        print "setting $k=$v\n" if $verbose;
        $vars{$k} = $v;
    }
    $vars{CASEDIR} = OpenQA::Utils::testcasedir($vars{DISTRI}, $vars{VERSION});
    save_vars(\%vars);

    # create tmpdir for qemu to write here
    my $tmpdir = "$pooldir/tmp";
    mkdir($tmpdir) unless (-d $tmpdir);

    my $child = fork();
    die "failed to fork: $!\n" unless defined $child;

    # for the status call
    $log_offset = 0;

    unless ($child) {
        $ENV{'TMPDIR'} = $tmpdir;
        printf "$$: WORKING %d\n", $job->{'id'};
        if (open(my $log, '>', "autoinst-log.txt")) {
            print $log "+++ worker notes +++\n";
            printf $log "start time: %s\n", strftime("%F %T", gmtime);
            printf $log "running on $hostname:%d ($sysname $release $version $machine)\n", $options{'instance'};
            close($log);
        }
        open STDOUT, ">>", "autoinst-log.txt";
        open STDERR, ">&STDOUT";
        exec "$isotovideo", '-d';
        die "exec failed: $!\n";
    }
    else {
        return { pid => $child };
    }

}

sub _kill_worker($) {
    my ($worker) = @_;

    return unless $worker;

    warn "killing $worker->{pid}\n";
    kill(SIGTERM, $worker->{pid});

    # don't leave here before the worker is dead
    my $pid = waitpid($worker->{pid}, 0);
    if ($pid == -1) {
        warn "waitpid returned error: $!\n";
    }

    $worker = undef;
}

sub _kill($) {
    my ($pid) = @_;
    my $n = kill(SIGTERM, $pid);
    for (my $i = 0; $n && $i < 5; ++$i) {
        sleep 1;
        $n = kill(SIGTERM, $pid);
    }
    if ($n) {
        warn "pid $pid didn't die, sending KILL";
        kill(SIGKILL, $pid);
    }
}

# set job to done. if priority is less than threshold duplicate it
# with worse priority so it can be picked up again.
sub job_incomplete($){
    my ($job) = @_;
    my %args;
    $args{dup_type_auto} = 1;

    printf "duplicating job %d\n", $job->{'id'};
    # make it less attractive so we don't get it again
    api_call('post', 'jobs/'.$job->{'id'}.'/duplicate', \%args);

    # set result after creating duplicate job so the chained jobs can survive
    api_call('post', 'jobs/'.$job->{'id'}.'/set_done', {result => 'incomplete'});

    clean_pool();
}

# check if results.json contains an overal result. If the latter is
# missing the worker probably crashed.
sub results {
    my $fn = "$testresults/results.json";
    my $ret;
    local $/;
    open(my $fh, '<', $fn) or return 0;
    my $json = {};
    eval {$json = decode_json(<$fh>);};
    warn "os-autoinst didn't write proper results.json" if $@;
    close($fh);
    return $json;
}

sub results_overall() {
    my $json = results();
    return $json->{'overall'};
}

sub clean_pool(){
    return if $options{'no-cleanup'};
    if (-e "$pooldir/qemu.pid") {
        print "QEMU should be dead - WASUP?\n";
        exit(1);
    }
    for my $file (<$pooldir/*>) {
        if (-d $file) {
            remove_tree($file);
        }
        else {
            unlink $file;
        }
    }
}

sub backup_testresults($){
    my $testresults = shift;
    for (my $i = 0; $i < 100; $i++) {
        if (rename($testresults, $testresults.".$i")) {
            return;
        }
    }
    remove_tree($testresults);
}

sub save_vars($) {
    my $vars = shift;
    die "cannot get environment variables!\n" unless $vars;
    my $fn = $pooldir . "/vars.json";
    unlink "$pooldir/vars.json" if -e "$pooldir/vars.json";
    open( my $fd, ">", $fn ) or die "can not write vars.json: $!\n";
    fcntl( $fd, F_SETLKW, pack( 'ssqql', F_WRLCK, 0, 0, 0, $$ ) ) or die "cannot lock vars.json: $!\n";
    truncate( $fd, 0 ) or die "cannot truncate vars.json: $!\n";

    print $fd to_json( \%$vars, { pretty => 1 } );
    close($fd);
}

sub get_capabilities {
    my $caps = {};
    my $query_cmd;

    if ($worker_settings->{ARCH}) {
        $caps->{cpu_arch} = $worker_settings->{ARCH};
    }
    else {
        open(LSCPU, "LC_ALL=C lscpu|");
        while (<LSCPU>) {
            chomp;
            if (m/Model name:\s+(.+)$/) {
                $caps->{cpu_modelname} = $1;
            }
            if (m/Architecture:\s+(.+)$/) {
                $caps->{cpu_arch} = $1;
            }
            if (m/CPU op-mode\(s\):\s+(.+)$/) {
                $caps->{cpu_opmode} = $1;
            }
        }
        close(LSCPU);
    }
    open(MEMINFO, "/proc/meminfo");
    while (<MEMINFO>) {
        chomp;
        if (m/MemTotal:\s+(\d+).+kB/) {
            my $mem_max = $1 ? $1 : '';
            $caps->{mem_max} = int($mem_max/1024) if $mem_max;
        }
    }
    close(MEMINFO);
    return $caps;
}

# function prototypes - needed since following functions interdepend on each other
sub start_job;
sub update_status;
sub check_backend;
sub verify_workerid;

sub check_job {
    return unless verify_workerid;
    if (!$job) {
        print "checking for job ...\n" if $verbose;
        my $res = api_call('post',"workers/$workerid/grab_job", $worker_caps) || { job => undef };
        $job = $res->{job};
        if ($job && $job->{id}) {
            # stop job check
            remove_timer('check_job');
            return start_job;
        }
        $job = undef;
    }
}

sub stop_job($) {
    my ($aborted) = @_;

    # we call this function in all situations, so better check
    return unless $job;

    print "stop_job $aborted\n" if $verbose;

    # stop all job related timers
    remove_timer('update_status');
    remove_timer('check_backend');
    remove_timer('job_timeout');

    _kill_worker($worker);

    my $name = $job->{'settings'}->{'NAME'};
    $aborted ||= 'done';

    if (open(my $log, '>>', "$results_dir/runlog.txt")) {
        if (fcntl($log, F_SETLKW, pack('ssqql', F_WRLCK, 0, 0, 0, $$))) {
            printf $log "%s finished to create %s: %s\n",strftime("%F %T", gmtime),$name, $aborted;
        }
        close($log);
    }

    my $job_done; # undef

    if ($aborted ne 'quit' && $aborted ne 'abort') {
        # collect uploaded logs
        my @uploaded_logfiles = <$pooldir/ulogs/*>;
        mkdir("$testresults/ulogs/");
        for my $uploaded_logfile (@uploaded_logfiles) {
            next unless -f $uploaded_logfile;
            unless(copy($uploaded_logfile, "$testresults/ulogs/")) {
                warn "can't copy ulog: $uploaded_logfile -> $testresults/ulogs/\n";
            }
        }
        if (open(my $log, '>>', "autoinst-log.txt")) {
            print $log "+++ worker notes +++\n";
            printf $log "end time: %s\n", strftime("%F %T", gmtime);
            print $log "result: $aborted\n";
            close $log;
        }
        for my $file (qw(video.ogv autoinst-log.txt vars.json serial0)) {
            # default serial output file called serial0
            my $ofile = $file;
            $ofile =~ s/serial0/serial0.txt/;
            unless (move("$pooldir/$file", join('/', $testresults, $ofile))) {
                warn "can't move $file: $!\n";
            }
        }

        if ($aborted eq 'obsolete') {
            printf "setting job %d to incomplete (obsolete)\n", $job->{'id'};
            api_call('post', 'jobs/'.$job->{'id'}.'/set_done', {result => 'incomplete', newbuild => 1});
            $job_done = 1;
        }
        elsif ($aborted eq 'cancel') {
            # not using job_incomplete here to avoid duplicate
            printf "setting job %d to incomplete (cancel)\n", $job->{'id'};
            api_call('post', 'jobs/'.$job->{'id'}.'/set_done', {result => 'incomplete'});
            $job_done = 1;
        }
        elsif ($aborted eq 'timeout') {
            printf "job %d spent more time than MAX_JOB_TIME\n", $job->{'id'};
        }
        elsif ($aborted eq 'done') { # not aborted
            # if there's no results.json start.pl probably died early, e.g. due to configuration
            # problem. Release the job so another worker may grab it.
            my $overall = results_overall() || '';
            # FIXME: this needs improvement
            if ($overall eq 'ok') {
                $overall = 'passed';
            }
            elsif ($overall eq 'fail') {
                $overall = 'failed';
            }
            else {
                $overall = 'incomplete';
            }
            printf "setting job %d to $overall\n", $job->{'id'};
            api_call('post', 'jobs/'.$job->{'id'}.'/set_done', {result => $overall});
            $job_done = 1;
        }
    }
    unless ($job_done) {
        job_incomplete($job);
    }
    warn sprintf("cleaning up %s...\n", $job->{'settings'}->{'NAME'});
    clean_pool();
    $job = undef;
    $worker = undef;
    $worker_start_time = undef;
    # immediatelly check for already scheduled job
    check_job();
    # and start backup checking for job if none was acquired
    add_timer('check_job', 10, \&check_job) unless ($job);
}

sub start_job {
    # update settings with worker-specific stuff
    @{$job->{'settings'}}{keys %$worker_settings} = values %$worker_settings;
    my $name = $job->{'settings'}->{'NAME'};
    printf "got job %d: %s\n", $job->{'id'}, $name;
    $max_job_time = $job->{'settings'}->{'MAX_JOB_TIME'} || 2*60*60; # 2h
    $testresults = join('/', $results_dir, $name);
    if (-l "$testresults") {
        unlink($testresults);
    }
    elsif (-e $testresults) {
        backup_testresults($testresults);
    }
    if (!mkdir($testresults)) {
        warn "mkdir $testresults: $!\n";
        return stop_job('setup failure');
    }
    if (!mkdir(join('/', $pooldir, 'testresults'))) {
        warn "mkdir $pooldir/testresults: $!\n";
        return stop_job('setup failure');
    }
    if (!symlink($testresults, join('/', $pooldir, 'testresults', $name))) {
        warn "symlink $testresults: $!\n";
        return stop_job('setup failure');
    }
    $worker = workit($job);
    unless ($worker) {
        warn "job is missing files, releasing job\n";
        return stop_job('setup failure');
    }
    $worker_start_time = time;
    if ($job && open(my $log, '>>', "$results_dir/runlog.txt")) {
        if (fcntl($log, F_SETLKW, pack('ssqql', F_WRLCK, 0, 0, 0, $$))) {
            my @s = map { sprintf("%s=%s", $_, $job->{'settings'}->{$_}) } grep { $_ ne 'ISO' && $_ ne 'NAME' } keys %{$job->{'settings'}};
            printf $log "%s started to create %s %s\n",strftime("%F %T", gmtime), $name, join(' ', @s);
        }
        close($log);
    }
    # start updating status - slow updates if livelog is not running
    add_timer('update_status', $status_updates_slow, \&update_status);
    # start backend checks
    add_timer('check_backend', 2, \&check_backend);
    # create job timeout timer
    add_timer(
        'job_timeout',
        $max_job_time,
        sub {
            # abort job if it takes too long
            if ($job) {
                warn sprintf("max job time exceeded, aborting %s ...\n", $job->{'settings'}->{'NAME'});
                stop_job('timeout');
            }
        },
        1
    );
}

sub log_snippet {
    my $file = "$pooldir/autoinst-log.txt";

    my $fd;
    unless (open($fd, '<:raw', $file)) {
        return {};
    }
    my $ret = {offset => $log_offset};

    sysseek($fd, $log_offset, Fcntl::SEEK_SET);
    sysread($fd, my $buf = '', 100000);
    $ret->{data} = $buf;
    $log_offset = sysseek($fd, 0, 1);
    close($fd);
    return $ret;
}

# uploads current data
sub update_status {
    return unless verify_workerid;
    return unless $job;
    my $status = {};

    $status->{'log'} = log_snippet;
    $status->{'results'} = results();
    api_call('post', 'jobs/'.$job->{id}.'/status', undef, {status => $status});
}

sub handle_commands {
    my ($tx, $msg) = @_;
    if ($msg eq 'quit') { # quit_worker and reschedule the job
        stop_job('quit');
    }
    elsif ($msg eq 'abort') { # the work is live and the job is rescheduled
        stop_job('abort');
    }
    elsif ($msg eq 'cancel') { # The jobs is droped and the work is still alive
        stop_job('cancel');
    }
    elsif ($msg eq 'obsolete') { # The jobs is droped and a new build job replaced it
        stop_job('obsolete');
    }
    elsif ($msg eq 'stop_waitforneedle') { # Plan: Enable interactive mode -- Now osautoinst decides what that means
        if ($worker) {
            if (open(my $f, '>', "$pooldir/stop_waitforneedle")) {
                close $f;
                print "waitforneedle will be stopped";
            }
            else {
                warn "can't stop waitforneedle: $!";
            }
        }
    }
    elsif ($msg eq 'reload_needles_and_retry') { #
        if ($worker) {
            if (open(my $f, '>', "$pooldir/reload_needles_and_retry")) {
                close $f;
                print "needles will be reloaded";
            }
            else {
                warn "can't reload needles: $!";
            }
        }
    }
    elsif ($msg eq 'enable_interactive_mode') {
        if ($worker) {
            if (open(my $f, '>', "$pooldir/interactive_mode")) {
                close $f;
                print "interactive mode enabled\n";
            }
            else {
                warn "can't enable interactive mode: $!";
            }
        }
    }
    elsif ($msg eq 'disable_interactive_mode') {
        if ($worker) {
            unlink("$pooldir/interactive_mode");
            print "interactive mode disabled\n";
        }
    }
    elsif ($msg eq 'continue_waitforneedle') {
        if ($worker) {
            unlink("$pooldir/stop_waitforneedle");
            print "continuing waitforneedle";
        }
    }
    elsif ($msg eq 'livelog_start') {
        # change update_status timer if $job running
        if ($worker) {
            change_timer('update_status', $status_updates_fast);
        }
    }
    elsif ($msg eq 'livelog_stop') {
        # change update_status timer
        if ($worker) {
            change_timer('update_status', $status_updates_slow);
        }
    }
    elsif ($msg eq 'ok') {
        # ignore keepalives, but dont' report as unknown
    }
    elsif ($msg eq 'job_available') {
        if (!$job) {
            check_job
        }
    }
    else {
        print STDERR "got unknown command $msg\n";
    }
}

sub verify_workerid {
    if (!$workerid) {
        $worker_caps = get_capabilities;
        $worker_caps->{host} = $hostname;
        $worker_caps->{instance} = $options{'instance'};
        $worker_caps->{backend} = $worker_settings->{'BACKEND'};

        my $res = api_call('post','workers', $worker_caps);
        return unless $res;
        $ENV{'WORKERID'} = $workerid = $res->{id};
        # recreate WebSocket connection, our id may have changed
        if ($ws) {
            $ws->finish;
            $ws = undef;
        }
    }
    if (!$ws) {
        my $ua_url = $url->clone();
        if ($url->scheme eq 'http') {
            $ua_url->scheme('ws');
        }
        else {
            $ua_url->scheme('wss');
        }
        $ua_url->path("workers/$workerid/ws");
        print "WEBSOCKET $ua_url\n" if $verbose;
        $ua->websocket(
            $ua_url => sub {
                my ($ua, $tx) = @_;
                if ($tx->is_websocket) {
                    $ws = $tx;
                    $tx->on(message => \&handle_commands);
                    $tx->on(
                        finish => sub {
                            print "closing websocket connection\n" if $verbose;
                            $ws = undef;
                        }
                    );
                }
                else {
                    my $err = $tx->error;
                    carp "Unable to upgrade connection to WebSocket: ".$err->{code}.". proxy_wstunnel enabled?" if defined $err;
                    $ws = undef;
                }
            }
        );
    }
    return $workerid;
}

sub ws_keepalive {
    #send ok keepalive so WebSocket connection is not inactive
    return unless $ws;
    $ws->send('ok');
}

sub check_backend {
    print "checking backend state ...\n" if $verbose;
    # abort job if backend crashed and reschedule it
    if(-e "$pooldir/backend.crashed") {
        unlink("$pooldir/backend.crashed");
        print STDERR "backend crashed ...\n";
        stop_job('crashed');
        if (open(my $fh, '<', "$pooldir/qemu.pid")) {
            local $/;
            my $pid = <$fh>;
            close $fh;
            if ($pid =~ /(\d+)/) {
                print STDERR "killing qemu $1\n";
                _kill($1);
            }
        }
        if (open(my $fh, '<', "$pooldir/os-autoinst.pid")) {
            local $/;
            my $pid = <$fh>;
            close $fh;
            if ($pid =~ /(\d+)/) {
                print STDERR "killing os-autoinst $1\n";
                _kill($1);
            }
        }
    }

    # check if the worker is still running
    my $pid = waitpid($worker->{pid}, WNOHANG);
    if ($verbose) {
        printf "waitpid %d returned %d\n", $worker->{pid}, $pid;
    }

    if ($pid == $worker->{pid}) {
        if ($?) {
            warn "child $pid died with exit status $?\n";
            stop_job('died');
        }
        else {
            stop_job('done');
        }
    }
}

sub main(){
    my $lockfd = lockit();

    $SIG{__DIE__} = sub { return if $^S; _kill_worker($worker); exit(1); };

    clean_pool();

    ## register worker at startup
    verify_workerid;

    ## initial Mojo::IO timers
    add_timer('ws_keepalive', 5, \&ws_keepalive);
    # backup check_job in case notification command does not get through
    add_timer('check_job', 10, \&check_job);

    # start event loop - this will block until stop is called
    Mojo::IOLoop->start;
    # cleanup on finish if necessary
    if ($job) {
        stop_job('quit');
        unlink($testresults);
    }
}

sub catch_exit{
    # send stop to event loop
    Mojo::IOLoop->stop;
}

$SIG{HUP} = \*catch_exit;
$SIG{TERM} = \*catch_exit;
$SIG{INT} = \*catch_exit;

main();

print "quit\n";
exit 0;
# vim: set sw=4 sts=4 et:
