#!/usr/bin/env perl
# Copyright (c) 2013 SUSE Linux Products GmbH
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

=head1 worker

worker - openQA worker daemon

=head1 SYNOPSIS

worker [OPTIONS]

=head1 OPTIONS

=over 4

=item B<--host> HOST

specify dispatcher/scheduler host to connect to

=item B<--instance> NR

specify instance number, ie pool directory to use

=item B<--key> <value>

specify the public key needed for API authentication

=item B<--secret> <value>

specify the secret key needed for API authentication

=item B<--isotovideo> PATH

path to isotovideo script, useful for running from git

=item B<--no-cleanup>

don't clean pool directory after job

=item B<--verbose>

verbose output

=item B<--help, -h>

print help

=back

=head1 DESCRIPTION

lorem ipsum ...

=head1 CONFIG FILE

L<OpenQA::API::V1::Client> tries to find a config file in
$OPENQA_CLIENT_CONFIG, ~/.config/openqa/client.conf or
/etc/openqa/client.conf and reads whatever comes first.
You can put key and secret in that config file.

Example:
  [openqa.example.com]
  key = foo
  secret = bar

=head1 SEE ALSO
L<OpenQA::API::V1::Client>

=cut

use strict;
use warnings;
use POSIX qw/:sys_wait_h strftime SIGTERM/;
use Data::Dump;
use JSON;
use Fcntl;
use File::Path qw/make_path remove_tree/;
use File::Copy qw(copy move);
use File::Copy::Recursive qw(dirmove);
use FindBin;
use Mojo::UserAgent;
use Mojo::URL;
use Carp;
use lib "$FindBin::Bin/../lib";
#use openqa;
use OpenQA::API::V1::Client;

my $max_job_time = 2*60*60; # 2h
my $openqa_base = "/var/lib/openqa";
my $pooldir;
my $isodir = "$openqa_base/factory/iso";
my $hdddir = "$openqa_base/hdd";
my $results_dir = "$openqa_base/testresults";
my $logupload_dir = "$openqa_base/logupload";

my $isotovideo = "/usr/lib/os-autoinst/tools/isotovideo";

my $keep_running = 1;
my $got_sigchld = 0;

use Getopt::Long;
Getopt::Long::Configure("no_ignore_case");

my %options;

sub usage($) {
	my $r = shift;
	eval "use Pod::Usage; pod2usage($r);";
	if ($@) {
		die "cannot display help, install perl(Pod::Usage)\n";
	}
}

GetOptions(
	\%options,
	"no-cleanup",
	"instance=i",
	"isotovideo=s",
	"host=s",
	"key:s",
	"secret:s",
	"verbose|v",
	"help|h",
) or usage(1);

usage(1) unless exists $options{'host'};
usage(0) if ($options{'help'});

my $verbose = $options{'verbose'};

$options{'instance'} ||= 0;

my $url;
if ($options{'host'} !~ '/') {
	$url = Mojo::URL->new();
	$url->host($options{'host'});
	$url->scheme('http');
} else {
	$url = Mojo::URL->new($options{'host'});
}
# Relative paths are appended to the existing one
$url->path('/api/v1/');

my $ua = OpenQA::API::V1::Client->new(api => $url->host);

unless ($ua->key && $ua->secret) {
	unless ($options{'key'} && $options{secret}) {
		die "key and secret are needed for the worker\n";
	}

	$ua->key($options{'key'});
	$ua->secret($options{'secret'});
}

$pooldir = $openqa_base.'/pool/'.($options{'instance'}||'manual');

# XXX: this should be sent to the scheduler to be included in the worker's table
$ENV{'QEMUPORT'} = ($options{'instance'})*10 + 20002;
$ENV{'VNC'}      = ($options{'instance'})    + 90;
$ENV{'OPENQA_HOSTNAME'} = $url->authority;

$isotovideo = $options{'isotovideo'} if $options{'isotovideo'};

# send a command to openQA API
sub api_call
{
	my $method = lc(shift);
	my $path = shift;
	my $params = shift;
	my $ua_url = $url->clone;

	$ua_url->path($path =~ s/^\///r);
	$ua_url->query($params) if $params;

	my $tries = 3;
	while (1) {
		my $tx = $ua->$method($ua_url);
		if ($tx->success) {
			return $tx->success->json;
		}
		--$tries;
		my ($err, $code) = $tx->error;
		my $msg = $code ? "$tries: $code response: $err" : "$tries: Connection error: $err";
		croak "$msg\n" unless $tries;
		carp "$msg";
		sleep 5;
	}
}

sub lockit()
{
	if (! -e $pooldir) {
		make_path($pooldir);
	}
	chdir $pooldir || die "cannot change directory to $pooldir: $!\n";
	open(my $lockfd, '>>', '.locked') or die "cannot open lock file: $!\n";
	unless (fcntl($lockfd, F_SETLK, pack('ssqql', F_WRLCK, 0, 0, 0, $$))) {
		die "$pooldir already locked\n";
	}
	$lockfd->autoflush(1);
	truncate($lockfd, 0);
	print $lockfd "$$\n";
	return $lockfd;
}

sub workit($)
{
	my $job = shift;
	my $iso = $job->{'settings'}->{'ISO'};
	return undef unless $iso;

	# XXX: this should come from the worker table. Only included
	# here for convenience when looking at the pool of
	# debugging.
	for my $i (qw/QEMUPORT VNC OPENQA_HOSTNAME/) {
		$job->{settings}->{$i} = $ENV{$i};
	}

	if (open(my $fh, '>', 'job.json')) {
		print $fh to_json($job, { pretty => 1 });
		close $fh;
	}

	$iso = join('/', $isodir, $iso);
	unless (-e $iso) {
		warn "$iso does not exist!\n";
		return undef;
	}
	$job->{'settings'}->{'ISO'} = $iso;

	my $nd = $job->{'settings'}->{'NUMDISKS'} || 2;
	for my $i (1..$nd) {
		my $hdd = $job->{'settings'}->{'HDD_$i'} || undef;
		if ($hdd) {
			$hdd = join('/', $hdddir, $hdd);
			unless (-e $hdd) {
				warn "$hdd does not exist!\n";
				return undef;
			}
			$job->{'settings'}->{'HDD_$i'} = $hdd;
		}
	}

	my $child = fork();
	die "failed to fork: $!\n" unless defined $child;
	unless ($child) {
		# just to make isotovideo happy
		unlink('env.sh');
		open(my $e, '>', 'env.sh') or die "can't open env.sh: $!\n";
		while (my ($k, $v) = each $job->{'settings'}) {
			print "setting $k=$v\n" if $verbose;
			$ENV{$k} = $v;
			# XXX: this assumes no quoting needed!
			printf $e "%s=\"%s\"\n", $k, $v;
		}
		close $e;
		printf "$$: WORKING %d\n", $job->{'id'};
		exec($isotovideo, $iso);
		die "exec failed: $!\n";
	} else {
		return $child;
	}
}

sub _kill_worker($)
{
	my $worker = shift;
	return unless $worker;
	for (1..3) {
		print "killing $worker\n";
		last unless $got_sigchld || kill(SIGTERM, $worker);
		sleep 2;
	}

	carp "worker didn't want to die!\n" unless $got_sigchld;
}

# set job to done. if priority is less than threshold duplicate it
# with worse priority so it can be picked up again.
sub job_incomplete($$$)
{
        my ($job, $prio_adjust, $result) = @_;
        api_call('post', 'jobs/'.$job->{'id'}.'/set_done', {result => 'incomplete'});
        if (!$prio_adjust || ($prio_adjust && $job->{'priority'} le 70)) {
                my %args;
                if ($prio_adjust) {
                    $job->{'priority'}++;
                    $args{prio} = $job->{'priority'};
                }
                printf "duplicating job %d, prio %d\n", $job->{'id'}, $job->{'priority'};
                # make it less attractive so we don't get it again
                api_call('post', 'jobs/'.$job->{'id'}.'/duplicate', \%args);
        }
}

# check if results.json contains an overal result. If the latter is
# missing the worker probably crashed.
sub results_overall($)
{
	my $fn = shift;
	my $ret;
	local $/;
	open(my $fh, '<', $fn) or return 0;
	my $json;
	eval {
		$json = decode_json(<$fh>);
	}; warn "os-autoinst didn't write proper results.json" if $@;
	$ret = $json->{'overall'} if $json && $json->{'overall'};
	close($fh);
	return $ret;
}

sub clean_pool($)
{
	return if $options{'no-cleanup'};
	my $job = shift;
	my $name = $job->{'settings'}->{'NAME'};
	remove_tree(
		"$logupload_dir/$name",
		"$pooldir/testresults",
		"$pooldir/video",
		"$pooldir/movie",
		"$pooldir/qemuscreenshot",
		"$pooldir/raid"
	);
}

sub backup_testresults($)
{
	my $testresults = shift;
	for (my $i = 0; $i < 100; $i++) {
		if (rename($testresults, $testresults.".$i")) {
			return;
		}
	}
	remove_tree($testresults);
}


sub main()
{
	my $lockfd = lockit();

	my $workerid = api_call('post', 'workers', {host => 'localhost', instance => $options{'instance'}, backend => 'qemu'})->{id};
	$ENV{'WORKERID'} = $workerid;

	my $job;
	my $worker;
	my $worker_start_time;
	my $testresults;
	my $aborted;
	my $retries;

	$SIG{__DIE__} = sub { return if $^S; _kill_worker($worker); exit(1); };

	while($keep_running) {
		my $cmds; # [[id, command], ... ]
		$cmds = api_call('get', "workers/$workerid/commands")->{commands};
		for my $cmd (@{$cmds||[]}) {
			if ($cmd->[1] eq 'quit') { # quit_worker and reschedule the job
				$keep_running = 0;
				if ($worker) {
					_kill_worker($worker);
                                        job_incomplete($job, 0, "worker quit");
					$aborted = 'quit';
				}
			} elsif ($cmd->[1] eq 'abort') { # the work is live and the job is rescheduled
				if ($worker) {
					_kill_worker($worker);
                                        api_call('post', 'jobs/'.$job->{'id'}.'/set_done', {result => 'incomplete'});
					$aborted = 'abort';
				}
			} elsif ($cmd->[1] eq 'cancel') { # The jobs is droped and the work is still alive
				if ($worker) {
					_kill_worker($worker);
					$aborted = 'cancel';
				}
			} elsif ($cmd->[1] eq 'stop_waitforneedle') { # Plan: Enable interactive mode -- Now osautoinst decides what that means
				if ($worker) {
					if (open(my $f, '>', "$pooldir/stop_waitforneedle")) {
						close $f;
						print "waitforneedle will be stopped";
					} else {
						warn "can't stop waitforneedle: $!";
					}
				}
			} elsif ($cmd->[1] eq 'reload_needles_and_retry') { #
				if ($worker) {
					if (open(my $f, '>', "$pooldir/reload_needles_and_retry")) {
						close $f;
						print "needles will be reloaded";
					} else {
						warn "can't reload needles: $!";
					}
				}
			} elsif ($cmd->[1] eq 'enable_interactive_mode') {
				if ($worker) {
					if (open(my $f, '>', "$pooldir/interactive_mode")) {
						close $f;
						print "interactive mode enabled\n";
					} else {
						warn "can't enable interactive mode: $!";
					}
				}
			} elsif ($cmd->[1] eq 'disable_interactive_mode') {
				if ($worker) {
					unlink("$pooldir/interactive_mode");
					print "interactive mode disabled\n";
				}
			} elsif ($cmd->[1] eq 'continue_waitforneedle') {
				if ($worker) {
					unlink("$pooldir/stop_waitforneedle");
					print "continuing waitforneedle";
				}
			} else {
				print STDERR "got unknown command $cmd->[1]\n";
			}
			api_call('delete', "workers/$workerid/commands/".$cmd->[0]);
		}

		# abort job if it takes too long
		if ($job && $worker_start_time && time-$worker_start_time > $max_job_time && !$aborted) {
			warn sprintf("max job time exceeded, aborting %s ...\n", $job->{'settings'}->{'NAME'});
			_kill_worker($worker);
			job_incomplete($job, 1, "time exceeded");
			$aborted = 'timeout';
		}

		if ($keep_running && !$job) {
			print "waiting for job ...\n" if $verbose;
			$job = api_call('post', "workers/$workerid/grab_job")->{job};
			unless ($job) {
				sleep 5;
				next;
			}
			my $name = $job->{'settings'}->{'NAME'};
			printf "got job %d: %s\n", $job->{'id'}, $name;
			$testresults = join('/', $results_dir, $name);
			if (-l "$testresults") {
				unlink($testresults);
			} elsif (-e $testresults) {
				backup_testresults($testresults);
			}
			symlink(join('/', $pooldir, 'testresults', $name), $testresults) or warn "symlink $testresults: $!\n";
			$worker = workit($job);
			unless ($worker) {
				warn "launching worker failed, releasing job\n";
				job_incomplete($job, 1, "worker died");
				$job = undef;
			}
			$worker_start_time = time;
			$aborted = undef;
			if ($job && open(my $log, '>>', "$results_dir/runlog.txt")) {
				if (fcntl($log, F_SETLKW, pack('ssqql', F_WRLCK, 0, 0, 0, $$))) {
					my @s = map { sprintf("%s=%s", $_, $job->{'settings'}->{$_}) } grep { $_ ne 'ISO' && $_ ne 'NAME' } keys %{$job->{'settings'}};
					printf $log "%s started to create %s %s\n",
						strftime("%F %T", gmtime), $name, join(' ', @s);
				}
				close($log);
			}
		}

		# we also enter here if the worker was killed intentionally
		if ($worker && $got_sigchld) {
			$got_sigchld = 0;
			my $pid = waitpid($worker, WNOHANG);
			die "huh? wrong child?\n" unless $pid == $worker;
			my $result = "ok";
			if ($?) {
				warn "child $pid died with exit status $?\n";
				$aborted = "died" unless $aborted;
			}

			$result = $aborted if $aborted;

			unlink($testresults); # can't move directory atomically to replace symlink
			my $name = $job->{'settings'}->{'NAME'};
			if (open(my $log, '>>', "$results_dir/runlog.txt")) {
				if (fcntl($log, F_SETLKW, pack('ssqql', F_WRLCK, 0, 0, 0, $$))) {
					printf $log "%s finished to create %s: %s\n",
						strftime("%F %T", gmtime),
						$name, $result;
				}
				close($log);
			}

			if (!$aborted || $aborted eq 'cancel' || $aborted eq 'timeout') {
				# collect uploaded logs
				my @uploaded_logfiles = <$logupload_dir/$name/*>;
				mkdir("$pooldir/testresults/$name/ulogs/");
				if(@uploaded_logfiles) {
					for my $uploaded_logfile (@uploaded_logfiles) {
						next unless -f $uploaded_logfile;
						unless(copy($uploaded_logfile, "$pooldir/testresults/$name/ulogs/")) {
							warn "can't copy ulog: $uploaded_logfile -> $pooldir/testresults/$name/ulogs/\n";
						}
					}
				}
				if(-e "$logupload_dir/$name/") {
					remove_tree("$logupload_dir/$name/"); # cleanup
				}

				unless (dirmove("$pooldir/testresults/$name", $testresults)) {
					warn "can't move test results $pooldir/testresults/$name -> $testresults: $!\n";
					$keep_running = 0;
				}
				unless (move("$pooldir/autoinst-log.txt", $testresults.'/autoinst-log.txt')) {
					warn "can't move log: $!\n";
					$keep_running = 0;
				}

				if (open(my $log, '>>', "$testresults/autoinst-log.txt")) {
					print $log "+++ worker notes +++\n";
					printf $log "time: %s\n", strftime("%F %T", gmtime);
					print $log "overall result: $result\n";
					close $log;
				}

				# if there's no results.json start.pl probably died early, e.g. due to configuration
				# problem. Release the job so another worker may grab it.
				my $overall = results_overall("$testresults/results.json");
				$result = $overall if !$aborted && $overall;
				# FIXME: this needs improvement
				if ($result eq 'ok') {
					$result = 'passed';
				} elsif ($result eq 'fail') {
					$result = 'failed';
				} else {
					$result = 'incomplete';
				}
				if (($aborted||'') eq 'cancel' || $overall) {
					printf "setting job %d to $result\n", $job->{'id'};
					api_call('post', 'jobs/'.$job->{'id'}.'/set_done', {result => $result});
				} else {
					job_incomplete($job, 1, $result);
				}
			} else {
			    job_incomplete($job, 1, $result);
			}
			warn sprintf("cleaning up %s...\n", $job->{'settings'}->{'NAME'});
			clean_pool($job);
			$job = undef;
			$worker = undef;
			$worker_start_time = undef;
		}

		print "waiting for some action ...\n" if $verbose;
		sleep 2 if $keep_running;
	}
	if ($job) {
		_kill_worker($worker);
		unlink($testresults);
                job_incomplete($job, 0, "worker quit");
		clean_pool($job);
	}
}

sub catch_exit
{
	$keep_running = 0;
}

sub catch_sigchld
{
	print "worker got SIGCHLD\n" if $verbose;
	$got_sigchld = 1;
}

$SIG{HUP} = \*catch_exit;
$SIG{TERM} = \*catch_exit;
$SIG{INT} = \*catch_exit;
$SIG{CHLD} = \*catch_sigchld;

main();

print "quit\n";
exit 0;
